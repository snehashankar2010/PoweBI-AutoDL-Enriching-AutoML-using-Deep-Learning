{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683bdea8",
   "metadata": {},
   "source": [
    "# AutoDL Implementation Part - 1\n",
    "#### Dataset Used: Keylogger_Detection Dataset\n",
    "#### (The preprocessed dataset of the original dataset is used for implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec448ac",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8377e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\hp\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Lib\\\\site-packages')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,accuracy_score\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras.layers.recurrent import LSTM, GRU,SimpleRNN\n",
    "import keras\n",
    "# Conv1D + LSTM\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling1D, Flatten, Bidirectional, SpatialDropout1D, LSTM, Dense, Flatten\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB6\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c634f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401908c",
   "metadata": {},
   "source": [
    "## Acessing Dataset from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c39bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Dataset Path: \n",
      "Keylogger_Updated.csv\n"
     ]
    }
   ],
   "source": [
    "path=input(\"Enter the Dataset Path: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6153ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Type of dataset:\n",
      "1.Text\n",
      "2.CSV\n",
      "3.Excel\n",
      "4.Image\n",
      "5.Audio\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "inp=int(input(\"Enter the Type of dataset:\\n1.Text\\n2.CSV\\n3.Excel\\n4.Image\\n5.Audio\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa542fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inp==1:\n",
    "    delim=input(\"Enter the delimiter present for given dataset:\")\n",
    "    df = pd.read_csv(path, delimiter=delim)\n",
    "elif inp==2:\n",
    "    df = pd.read_csv(path)\n",
    "elif inp==3:  \n",
    "    df = pd.read_excel(path)\n",
    "elif inp==4:\n",
    "    Image_Width = 512\n",
    "    Image_Height = 512\n",
    "    Image_Size = (Image_Width, Image_Height)\n",
    "    train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                  rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,)\n",
    "    test_generator = test_datagen.flow_from_directory(path,\n",
    "                                                  target_size=Image_Size,\n",
    "                                                  batch_size = 32,\n",
    "                                                  class_mode='categorical')\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "elif inp==5:\n",
    "    print(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d05e70",
   "metadata": {},
   "source": [
    "## Reading the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f84e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.210447</td>\n",
       "      <td>-0.368579</td>\n",
       "      <td>-0.468868</td>\n",
       "      <td>0.042412</td>\n",
       "      <td>-0.004811</td>\n",
       "      <td>-0.036722</td>\n",
       "      <td>-0.013233</td>\n",
       "      <td>-0.038629</td>\n",
       "      <td>-0.021233</td>\n",
       "      <td>-0.212203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>-0.063066</td>\n",
       "      <td>-0.175005</td>\n",
       "      <td>-0.173854</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>-0.121636</td>\n",
       "      <td>-0.296481</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828487</td>\n",
       "      <td>-0.368579</td>\n",
       "      <td>-0.468868</td>\n",
       "      <td>-0.465677</td>\n",
       "      <td>0.945480</td>\n",
       "      <td>0.575336</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>0.556642</td>\n",
       "      <td>0.815442</td>\n",
       "      <td>-0.212203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>-0.063066</td>\n",
       "      <td>-0.175005</td>\n",
       "      <td>-0.173854</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>-0.121636</td>\n",
       "      <td>-0.296481</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.027848</td>\n",
       "      <td>2.839488</td>\n",
       "      <td>-0.468868</td>\n",
       "      <td>-0.483831</td>\n",
       "      <td>-0.076338</td>\n",
       "      <td>-0.055364</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.046536</td>\n",
       "      <td>-0.435509</td>\n",
       "      <td>-0.212203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>-0.063066</td>\n",
       "      <td>-0.175005</td>\n",
       "      <td>-0.173854</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>-0.121636</td>\n",
       "      <td>-0.296481</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.821057</td>\n",
       "      <td>-0.393449</td>\n",
       "      <td>2.036972</td>\n",
       "      <td>-0.460353</td>\n",
       "      <td>-0.086556</td>\n",
       "      <td>-0.052257</td>\n",
       "      <td>-0.018736</td>\n",
       "      <td>-0.046050</td>\n",
       "      <td>-0.478832</td>\n",
       "      <td>0.522899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>-0.063066</td>\n",
       "      <td>-0.175005</td>\n",
       "      <td>-0.173854</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>-0.121636</td>\n",
       "      <td>-0.296481</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.759549</td>\n",
       "      <td>-0.368579</td>\n",
       "      <td>-0.468868</td>\n",
       "      <td>-0.166949</td>\n",
       "      <td>-0.066120</td>\n",
       "      <td>-0.055364</td>\n",
       "      <td>-0.019463</td>\n",
       "      <td>-0.046536</td>\n",
       "      <td>-0.584432</td>\n",
       "      <td>-0.212203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>-0.183877</td>\n",
       "      <td>-0.063066</td>\n",
       "      <td>-0.175005</td>\n",
       "      <td>-0.173854</td>\n",
       "      <td>-0.290551</td>\n",
       "      <td>-0.121636</td>\n",
       "      <td>-0.296481</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Port   Destination Port   Protocol   Flow Duration  \\\n",
       "0     -0.210447          -0.368579  -0.468868        0.042412   \n",
       "1      0.828487          -0.368579  -0.468868       -0.465677   \n",
       "2     -2.027848           2.839488  -0.468868       -0.483831   \n",
       "3     -0.821057          -0.393449   2.036972       -0.460353   \n",
       "4      0.759549          -0.368579  -0.468868       -0.166949   \n",
       "\n",
       "    Total Fwd Packets   Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0           -0.004811                -0.036722                    -0.013233   \n",
       "1            0.945480                 0.575336                    -0.004001   \n",
       "2           -0.076338                -0.055364                    -0.018437   \n",
       "3           -0.086556                -0.052257                    -0.018736   \n",
       "4           -0.066120                -0.055364                    -0.019463   \n",
       "\n",
       "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "0                     -0.038629               -0.021233   \n",
       "1                      0.556642                0.815442   \n",
       "2                     -0.046536               -0.435509   \n",
       "3                     -0.046050               -0.478832   \n",
       "4                     -0.046536               -0.584432   \n",
       "\n",
       "    Fwd Packet Length Min  ...   min_seg_size_forward  Active Mean  \\\n",
       "0               -0.212203  ...               0.004137    -0.183877   \n",
       "1               -0.212203  ...               0.004137    -0.183877   \n",
       "2               -0.212203  ...               0.004137    -0.183877   \n",
       "3                0.522899  ...               0.004137    -0.183877   \n",
       "4               -0.212203  ...               0.004135    -0.183877   \n",
       "\n",
       "    Active Std   Active Max   Active Min  Idle Mean   Idle Std   Idle Max  \\\n",
       "0    -0.063066    -0.175005    -0.173854  -0.290551  -0.121636  -0.296481   \n",
       "1    -0.063066    -0.175005    -0.173854  -0.290551  -0.121636  -0.296481   \n",
       "2    -0.063066    -0.175005    -0.173854  -0.290551  -0.121636  -0.296481   \n",
       "3    -0.063066    -0.175005    -0.173854  -0.290551  -0.121636  -0.296481   \n",
       "4    -0.063066    -0.175005    -0.173854  -0.290551  -0.121636  -0.296481   \n",
       "\n",
       "    Idle Min  label  \n",
       "0  -0.277622      0  \n",
       "1  -0.277622      0  \n",
       "2  -0.277622      0  \n",
       "3  -0.277622      0  \n",
       "4  -0.277622      0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09b00ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    308813\n",
       "1    214782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66b4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=['label']\n",
    "features = [c for c in df.columns if c!=\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b98dc",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c085d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523595, 67), (523595, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features].values # Features\n",
    "y = df[target].values # Target\n",
    "\n",
    "X=X.astype(np.float32)\n",
    "y=y.astype(np.float32)\n",
    "\n",
    "X.shape,y.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7280d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48eccdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418876, 67), (104719, 67), (418876, 1), (104719, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd640a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels = []\n",
    "DLhistory=[]\n",
    "AUCVal=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d49dee",
   "metadata": {},
   "source": [
    "# Deep Learning Model 1 -ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9f76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "batch_size=512\n",
    "epochs = 1000\n",
    "\n",
    "model_save = ModelCheckpoint('./Keylogging.h5', \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = True,\n",
    "                             monitor = 'val_loss', \n",
    "                             mode = 'min', verbose = 1)\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n",
    "                           patience = 50, mode = 'min', verbose = 1,\n",
    "                           restore_best_weights = True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.75, \n",
    "                              patience = 10, min_delta = 0.001, \n",
    "                              mode = 'min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b54c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def Create_Model_ANN(num_columns, num_labels,learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_dim=num_columns, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_labels,activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #adam = Adam(lr=learning_rate)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam,metrics=[keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = Create_Model_ANN(X_test.shape[1], 1,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3892d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=X_train.shape[1] # 50\n",
    "\n",
    "model1 = keras.Sequential()\n",
    "# Add input layer 50 \n",
    "\n",
    "w0=model.layers[0].get_weights()[0][:,:]\n",
    "b0=model.layers[0].get_weights()[1]\n",
    "\n",
    "model1.add(Dense(64,input_dim=input_size, activation='relu'))\n",
    "model1.layers[0].set_weights([w0, b0])\n",
    "\n",
    "# Add trained layers (with weight)\n",
    "for layer in model.layers[1:7]:\n",
    "    model1.add(layer)\n",
    "    \n",
    "# add output layer  sigmoid or softmax..    \n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "#model_new.layers[0].set_weights([w0, b0])\n",
    "\n",
    "adam = Adam(lr=learning_rate)\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam,metrics=[keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a8bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 64)                4352      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,825\n",
      "Trainable params: 349,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c3d978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.6458 - auc: 0.6267\n",
      "Epoch 1: val_loss improved from inf to 0.63850, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 16ms/step - loss: 0.6458 - auc: 0.6267 - val_loss: 0.6385 - val_auc: 0.6474 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.6274 - auc: 0.6563\n",
      "Epoch 2: val_loss improved from 0.63850 to 0.62237, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.6273 - auc: 0.6563 - val_loss: 0.6224 - val_auc: 0.6643 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.6189 - auc: 0.6692\n",
      "Epoch 3: val_loss improved from 0.62237 to 0.61735, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.6188 - auc: 0.6692 - val_loss: 0.6173 - val_auc: 0.6730 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.6121 - auc: 0.6787\n",
      "Epoch 4: val_loss improved from 0.61735 to 0.61335, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.6121 - auc: 0.6787 - val_loss: 0.6134 - val_auc: 0.6770 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.6056 - auc: 0.6875\n",
      "Epoch 5: val_loss improved from 0.61335 to 0.60459, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.6056 - auc: 0.6876 - val_loss: 0.6046 - val_auc: 0.6897 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.6000 - auc: 0.6951\n",
      "Epoch 6: val_loss improved from 0.60459 to 0.60020, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.6000 - auc: 0.6951 - val_loss: 0.6002 - val_auc: 0.6968 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5950 - auc: 0.7014\n",
      "Epoch 7: val_loss improved from 0.60020 to 0.59950, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.5949 - auc: 0.7015 - val_loss: 0.5995 - val_auc: 0.6980 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5903 - auc: 0.7075\n",
      "Epoch 8: val_loss improved from 0.59950 to 0.59021, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5903 - auc: 0.7074 - val_loss: 0.5902 - val_auc: 0.7097 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5859 - auc: 0.7127\n",
      "Epoch 9: val_loss improved from 0.59021 to 0.58921, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 13s 16ms/step - loss: 0.5859 - auc: 0.7127 - val_loss: 0.5892 - val_auc: 0.7124 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5809 - auc: 0.7182\n",
      "Epoch 10: val_loss improved from 0.58921 to 0.58222, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 13s 16ms/step - loss: 0.5809 - auc: 0.7182 - val_loss: 0.5822 - val_auc: 0.7192 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5769 - auc: 0.7235\n",
      "Epoch 11: val_loss improved from 0.58222 to 0.58178, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5769 - auc: 0.7235 - val_loss: 0.5818 - val_auc: 0.7201 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5718 - auc: 0.7289\n",
      "Epoch 12: val_loss improved from 0.58178 to 0.57462, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 13s 16ms/step - loss: 0.5718 - auc: 0.7289 - val_loss: 0.5746 - val_auc: 0.7262 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5687 - auc: 0.7326\n",
      "Epoch 13: val_loss did not improve from 0.57462\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.5687 - auc: 0.7326 - val_loss: 0.5767 - val_auc: 0.7244 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.5645 - auc: 0.7372\n",
      "Epoch 14: val_loss improved from 0.57462 to 0.56890, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.5645 - auc: 0.7372 - val_loss: 0.5689 - val_auc: 0.7333 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5603 - auc: 0.7421\n",
      "Epoch 15: val_loss improved from 0.56890 to 0.56234, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5603 - auc: 0.7421 - val_loss: 0.5623 - val_auc: 0.7399 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5570 - auc: 0.7460\n",
      "Epoch 16: val_loss improved from 0.56234 to 0.55733, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5570 - auc: 0.7461 - val_loss: 0.5573 - val_auc: 0.7468 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5531 - auc: 0.7497\n",
      "Epoch 17: val_loss did not improve from 0.55733\n",
      "819/819 [==============================] - 13s 16ms/step - loss: 0.5531 - auc: 0.7497 - val_loss: 0.5620 - val_auc: 0.7423 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5497 - auc: 0.7537\n",
      "Epoch 18: val_loss improved from 0.55733 to 0.55414, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5497 - auc: 0.7537 - val_loss: 0.5541 - val_auc: 0.7505 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5457 - auc: 0.7578\n",
      "Epoch 19: val_loss did not improve from 0.55414\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5457 - auc: 0.7577 - val_loss: 0.5546 - val_auc: 0.7503 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5425 - auc: 0.7615\n",
      "Epoch 20: val_loss improved from 0.55414 to 0.54598, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 13s 16ms/step - loss: 0.5424 - auc: 0.7616 - val_loss: 0.5460 - val_auc: 0.7593 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5397 - auc: 0.7640\n",
      "Epoch 21: val_loss did not improve from 0.54598\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5396 - auc: 0.7640 - val_loss: 0.5527 - val_auc: 0.7533 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.5363 - auc: 0.7675\n",
      "Epoch 22: val_loss improved from 0.54598 to 0.54269, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5363 - auc: 0.7675 - val_loss: 0.5427 - val_auc: 0.7637 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5328 - auc: 0.7707\n",
      "Epoch 23: val_loss did not improve from 0.54269\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.5328 - auc: 0.7707 - val_loss: 0.5529 - val_auc: 0.7552 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5304 - auc: 0.7732\n",
      "Epoch 24: val_loss improved from 0.54269 to 0.53970, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5304 - auc: 0.7732 - val_loss: 0.5397 - val_auc: 0.7678 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5281 - auc: 0.7756\n",
      "Epoch 25: val_loss improved from 0.53970 to 0.53935, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5281 - auc: 0.7756 - val_loss: 0.5394 - val_auc: 0.7674 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5244 - auc: 0.7788\n",
      "Epoch 26: val_loss improved from 0.53935 to 0.53798, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5244 - auc: 0.7788 - val_loss: 0.5380 - val_auc: 0.7706 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5219 - auc: 0.7813\n",
      "Epoch 27: val_loss improved from 0.53798 to 0.53068, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.5219 - auc: 0.7813 - val_loss: 0.5307 - val_auc: 0.7749 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5195 - auc: 0.7834\n",
      "Epoch 28: val_loss improved from 0.53068 to 0.53033, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.5195 - auc: 0.7835 - val_loss: 0.5303 - val_auc: 0.7764 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.5165 - auc: 0.7868\n",
      "Epoch 29: val_loss improved from 0.53033 to 0.52757, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.5165 - auc: 0.7868 - val_loss: 0.5276 - val_auc: 0.7781 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5136 - auc: 0.7892\n",
      "Epoch 30: val_loss improved from 0.52757 to 0.52715, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5135 - auc: 0.7893 - val_loss: 0.5272 - val_auc: 0.7799 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.5113 - auc: 0.7910\n",
      "Epoch 31: val_loss improved from 0.52715 to 0.52565, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5113 - auc: 0.7910 - val_loss: 0.5256 - val_auc: 0.7815 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.5101 - auc: 0.7923\n",
      "Epoch 32: val_loss did not improve from 0.52565\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.5101 - auc: 0.7923 - val_loss: 0.5278 - val_auc: 0.7785 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5073 - auc: 0.7943\n",
      "Epoch 33: val_loss improved from 0.52565 to 0.52294, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.5073 - auc: 0.7943 - val_loss: 0.5229 - val_auc: 0.7840 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5052 - auc: 0.7967\n",
      "Epoch 34: val_loss improved from 0.52294 to 0.52080, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.5051 - auc: 0.7968 - val_loss: 0.5208 - val_auc: 0.7880 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.5032 - auc: 0.7989\n",
      "Epoch 35: val_loss improved from 0.52080 to 0.52040, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.5032 - auc: 0.7989 - val_loss: 0.5204 - val_auc: 0.7855 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.5006 - auc: 0.8010\n",
      "Epoch 36: val_loss improved from 0.52040 to 0.51905, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.5006 - auc: 0.8011 - val_loss: 0.5191 - val_auc: 0.7899 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4977 - auc: 0.8034\n",
      "Epoch 37: val_loss improved from 0.51905 to 0.51789, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.4978 - auc: 0.8033 - val_loss: 0.5179 - val_auc: 0.7894 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4959 - auc: 0.8053\n",
      "Epoch 38: val_loss improved from 0.51789 to 0.51629, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.4959 - auc: 0.8053 - val_loss: 0.5163 - val_auc: 0.7934 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4954 - auc: 0.8060\n",
      "Epoch 39: val_loss did not improve from 0.51629\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.4954 - auc: 0.8059 - val_loss: 0.5176 - val_auc: 0.7928 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4928 - auc: 0.8082\n",
      "Epoch 40: val_loss improved from 0.51629 to 0.51357, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4929 - auc: 0.8081 - val_loss: 0.5136 - val_auc: 0.7938 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4901 - auc: 0.8101\n",
      "Epoch 41: val_loss improved from 0.51357 to 0.50837, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4901 - auc: 0.8101 - val_loss: 0.5084 - val_auc: 0.8000 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4893 - auc: 0.8107\n",
      "Epoch 42: val_loss did not improve from 0.50837\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4893 - auc: 0.8107 - val_loss: 0.5143 - val_auc: 0.7973 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4880 - auc: 0.8123\n",
      "Epoch 43: val_loss did not improve from 0.50837\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4879 - auc: 0.8123 - val_loss: 0.5103 - val_auc: 0.7988 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4853 - auc: 0.8143\n",
      "Epoch 44: val_loss did not improve from 0.50837\n",
      "819/819 [==============================] - 20s 24ms/step - loss: 0.4853 - auc: 0.8144 - val_loss: 0.5087 - val_auc: 0.7996 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4836 - auc: 0.8160\n",
      "Epoch 45: val_loss did not improve from 0.50837\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.4836 - auc: 0.8160 - val_loss: 0.5091 - val_auc: 0.8023 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4828 - auc: 0.8167\n",
      "Epoch 46: val_loss improved from 0.50837 to 0.50769, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4828 - auc: 0.8167 - val_loss: 0.5077 - val_auc: 0.8005 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4803 - auc: 0.8189\n",
      "Epoch 47: val_loss improved from 0.50769 to 0.49958, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4803 - auc: 0.8189 - val_loss: 0.4996 - val_auc: 0.8070 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4798 - auc: 0.8193\n",
      "Epoch 48: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4798 - auc: 0.8193 - val_loss: 0.4999 - val_auc: 0.8085 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4774 - auc: 0.8212\n",
      "Epoch 49: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4774 - auc: 0.8212 - val_loss: 0.5049 - val_auc: 0.8040 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4762 - auc: 0.8223\n",
      "Epoch 50: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4761 - auc: 0.8223 - val_loss: 0.5007 - val_auc: 0.8077 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4776 - auc: 0.8207\n",
      "Epoch 51: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4776 - auc: 0.8207 - val_loss: 0.5030 - val_auc: 0.8073 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4765 - auc: 0.8222\n",
      "Epoch 52: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4765 - auc: 0.8223 - val_loss: 0.5010 - val_auc: 0.8086 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4726 - auc: 0.8253\n",
      "Epoch 53: val_loss did not improve from 0.49958\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4726 - auc: 0.8253 - val_loss: 0.5081 - val_auc: 0.8052 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4713 - auc: 0.8266\n",
      "Epoch 54: val_loss improved from 0.49958 to 0.49597, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4712 - auc: 0.8266 - val_loss: 0.4960 - val_auc: 0.8147 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4693 - auc: 0.8278\n",
      "Epoch 55: val_loss did not improve from 0.49597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4692 - auc: 0.8278 - val_loss: 0.4982 - val_auc: 0.8136 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4685 - auc: 0.8287\n",
      "Epoch 56: val_loss did not improve from 0.49597\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.4684 - auc: 0.8287 - val_loss: 0.4975 - val_auc: 0.8141 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4663 - auc: 0.8306\n",
      "Epoch 57: val_loss improved from 0.49597 to 0.49508, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4664 - auc: 0.8305 - val_loss: 0.4951 - val_auc: 0.8152 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4655 - auc: 0.8312\n",
      "Epoch 58: val_loss improved from 0.49508 to 0.49234, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4655 - auc: 0.8312 - val_loss: 0.4923 - val_auc: 0.8186 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4644 - auc: 0.8322\n",
      "Epoch 59: val_loss did not improve from 0.49234\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4643 - auc: 0.8323 - val_loss: 0.4958 - val_auc: 0.8120 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4627 - auc: 0.8338\n",
      "Epoch 60: val_loss improved from 0.49234 to 0.48630, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4627 - auc: 0.8338 - val_loss: 0.4863 - val_auc: 0.8233 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4620 - auc: 0.8343\n",
      "Epoch 61: val_loss did not improve from 0.48630\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4620 - auc: 0.8342 - val_loss: 0.4911 - val_auc: 0.8197 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4591 - auc: 0.8364\n",
      "Epoch 62: val_loss did not improve from 0.48630\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4591 - auc: 0.8364 - val_loss: 0.4889 - val_auc: 0.8214 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4598 - auc: 0.8361\n",
      "Epoch 63: val_loss improved from 0.48630 to 0.48528, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4598 - auc: 0.8360 - val_loss: 0.4853 - val_auc: 0.8248 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4574 - auc: 0.8382\n",
      "Epoch 64: val_loss did not improve from 0.48528\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4574 - auc: 0.8382 - val_loss: 0.4956 - val_auc: 0.8186 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4581 - auc: 0.8386\n",
      "Epoch 65: val_loss did not improve from 0.48528\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.4580 - auc: 0.8386 - val_loss: 0.4864 - val_auc: 0.8231 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4549 - auc: 0.8397\n",
      "Epoch 66: val_loss improved from 0.48528 to 0.48447, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4550 - auc: 0.8397 - val_loss: 0.4845 - val_auc: 0.8244 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4539 - auc: 0.8404\n",
      "Epoch 67: val_loss did not improve from 0.48447\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4540 - auc: 0.8404 - val_loss: 0.4881 - val_auc: 0.8210 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4533 - auc: 0.8410\n",
      "Epoch 68: val_loss did not improve from 0.48447\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4533 - auc: 0.8411 - val_loss: 0.4864 - val_auc: 0.8250 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4522 - auc: 0.8423\n",
      "Epoch 69: val_loss improved from 0.48447 to 0.48408, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4522 - auc: 0.8423 - val_loss: 0.4841 - val_auc: 0.8260 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4508 - auc: 0.8433\n",
      "Epoch 70: val_loss improved from 0.48408 to 0.47833, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4508 - auc: 0.8433 - val_loss: 0.4783 - val_auc: 0.8307 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4490 - auc: 0.8445\n",
      "Epoch 71: val_loss did not improve from 0.47833\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.4490 - auc: 0.8445 - val_loss: 0.4840 - val_auc: 0.8267 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4485 - auc: 0.8451\n",
      "Epoch 72: val_loss did not improve from 0.47833\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4486 - auc: 0.8451 - val_loss: 0.4823 - val_auc: 0.8286 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4480 - auc: 0.8455\n",
      "Epoch 73: val_loss improved from 0.47833 to 0.47575, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4480 - auc: 0.8455 - val_loss: 0.4758 - val_auc: 0.8329 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4463 - auc: 0.8463\n",
      "Epoch 74: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4463 - auc: 0.8463 - val_loss: 0.4833 - val_auc: 0.8287 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4460 - auc: 0.8471\n",
      "Epoch 75: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4460 - auc: 0.8471 - val_loss: 0.4799 - val_auc: 0.8315 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4443 - auc: 0.8485\n",
      "Epoch 76: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4443 - auc: 0.8485 - val_loss: 0.4759 - val_auc: 0.8330 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4431 - auc: 0.8492\n",
      "Epoch 77: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4431 - auc: 0.8492 - val_loss: 0.4814 - val_auc: 0.8306 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4442 - auc: 0.8488\n",
      "Epoch 78: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4441 - auc: 0.8488 - val_loss: 0.4790 - val_auc: 0.8318 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4422 - auc: 0.8506\n",
      "Epoch 79: val_loss did not improve from 0.47575\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.4422 - auc: 0.8506 - val_loss: 0.4766 - val_auc: 0.8331 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4402 - auc: 0.8515\n",
      "Epoch 80: val_loss improved from 0.47575 to 0.47511, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 0.4402 - auc: 0.8515 - val_loss: 0.4751 - val_auc: 0.8349 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4397 - auc: 0.8519\n",
      "Epoch 81: val_loss improved from 0.47511 to 0.47372, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 22s 27ms/step - loss: 0.4396 - auc: 0.8520 - val_loss: 0.4737 - val_auc: 0.8368 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4379 - auc: 0.8531\n",
      "Epoch 82: val_loss improved from 0.47372 to 0.47189, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 23s 28ms/step - loss: 0.4379 - auc: 0.8531 - val_loss: 0.4719 - val_auc: 0.8376 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4374 - auc: 0.8536\n",
      "Epoch 83: val_loss did not improve from 0.47189\n",
      "819/819 [==============================] - 22s 26ms/step - loss: 0.4374 - auc: 0.8536 - val_loss: 0.4794 - val_auc: 0.8336 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4379 - auc: 0.8536\n",
      "Epoch 84: val_loss did not improve from 0.47189\n",
      "819/819 [==============================] - 23s 28ms/step - loss: 0.4379 - auc: 0.8536 - val_loss: 0.4811 - val_auc: 0.8322 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4358 - auc: 0.8552\n",
      "Epoch 85: val_loss improved from 0.47189 to 0.47124, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 22s 27ms/step - loss: 0.4358 - auc: 0.8552 - val_loss: 0.4712 - val_auc: 0.8379 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4354 - auc: 0.8557\n",
      "Epoch 86: val_loss did not improve from 0.47124\n",
      "819/819 [==============================] - 25s 31ms/step - loss: 0.4354 - auc: 0.8557 - val_loss: 0.4714 - val_auc: 0.8394 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4339 - auc: 0.8563\n",
      "Epoch 87: val_loss did not improve from 0.47124\n",
      "819/819 [==============================] - 22s 26ms/step - loss: 0.4339 - auc: 0.8563 - val_loss: 0.4783 - val_auc: 0.8333 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4334 - auc: 0.8569\n",
      "Epoch 88: val_loss did not improve from 0.47124\n",
      "819/819 [==============================] - 23s 28ms/step - loss: 0.4334 - auc: 0.8569 - val_loss: 0.4748 - val_auc: 0.8390 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4323 - auc: 0.8577\n",
      "Epoch 89: val_loss improved from 0.47124 to 0.46930, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 0.4323 - auc: 0.8577 - val_loss: 0.4693 - val_auc: 0.8406 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4310 - auc: 0.8589\n",
      "Epoch 90: val_loss improved from 0.46930 to 0.46775, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 22s 27ms/step - loss: 0.4310 - auc: 0.8589 - val_loss: 0.4678 - val_auc: 0.8422 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4298 - auc: 0.8596\n",
      "Epoch 91: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 21s 26ms/step - loss: 0.4298 - auc: 0.8596 - val_loss: 0.4761 - val_auc: 0.8383 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4302 - auc: 0.8596\n",
      "Epoch 92: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.4301 - auc: 0.8597 - val_loss: 0.4706 - val_auc: 0.8404 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4285 - auc: 0.8604\n",
      "Epoch 93: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.4285 - auc: 0.8604 - val_loss: 0.4708 - val_auc: 0.8413 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4270 - auc: 0.8614\n",
      "Epoch 94: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4270 - auc: 0.8613 - val_loss: 0.4721 - val_auc: 0.8404 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4274 - auc: 0.8613\n",
      "Epoch 95: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4274 - auc: 0.8613 - val_loss: 0.4714 - val_auc: 0.8413 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4250 - auc: 0.8630\n",
      "Epoch 96: val_loss did not improve from 0.46775\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4250 - auc: 0.8630 - val_loss: 0.4682 - val_auc: 0.8434 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4258 - auc: 0.8627\n",
      "Epoch 97: val_loss improved from 0.46775 to 0.46724, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4258 - auc: 0.8627 - val_loss: 0.4672 - val_auc: 0.8455 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4237 - auc: 0.8640\n",
      "Epoch 98: val_loss improved from 0.46724 to 0.46433, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4237 - auc: 0.8640 - val_loss: 0.4643 - val_auc: 0.8456 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4239 - auc: 0.8637\n",
      "Epoch 99: val_loss did not improve from 0.46433\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4239 - auc: 0.8637 - val_loss: 0.4676 - val_auc: 0.8463 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4245 - auc: 0.8638\n",
      "Epoch 100: val_loss did not improve from 0.46433\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4245 - auc: 0.8638 - val_loss: 0.4658 - val_auc: 0.8462 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4226 - auc: 0.8657\n",
      "Epoch 101: val_loss did not improve from 0.46433\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4226 - auc: 0.8657 - val_loss: 0.4655 - val_auc: 0.8454 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4205 - auc: 0.8662\n",
      "Epoch 102: val_loss did not improve from 0.46433\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4205 - auc: 0.8662 - val_loss: 0.4746 - val_auc: 0.8394 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4197 - auc: 0.8666\n",
      "Epoch 103: val_loss improved from 0.46433 to 0.46389, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4197 - auc: 0.8666 - val_loss: 0.4639 - val_auc: 0.8483 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4184 - auc: 0.8676\n",
      "Epoch 104: val_loss improved from 0.46389 to 0.46293, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4184 - auc: 0.8676 - val_loss: 0.4629 - val_auc: 0.8488 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4182 - auc: 0.8683\n",
      "Epoch 105: val_loss improved from 0.46293 to 0.46241, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4182 - auc: 0.8683 - val_loss: 0.4624 - val_auc: 0.8497 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "815/819 [============================>.] - ETA: 0s - loss: 0.4177 - auc: 0.8686\n",
      "Epoch 106: val_loss did not improve from 0.46241\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4177 - auc: 0.8686 - val_loss: 0.4675 - val_auc: 0.8460 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4166 - auc: 0.8694\n",
      "Epoch 107: val_loss improved from 0.46241 to 0.45956, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4166 - auc: 0.8694 - val_loss: 0.4596 - val_auc: 0.8515 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4157 - auc: 0.8697\n",
      "Epoch 108: val_loss did not improve from 0.45956\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4157 - auc: 0.8696 - val_loss: 0.4682 - val_auc: 0.8462 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4151 - auc: 0.8700\n",
      "Epoch 109: val_loss did not improve from 0.45956\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4151 - auc: 0.8700 - val_loss: 0.4637 - val_auc: 0.8522 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4157 - auc: 0.8701\n",
      "Epoch 110: val_loss improved from 0.45956 to 0.45887, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.4157 - auc: 0.8701 - val_loss: 0.4589 - val_auc: 0.8517 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4139 - auc: 0.8711\n",
      "Epoch 111: val_loss improved from 0.45887 to 0.45764, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.4139 - auc: 0.8711 - val_loss: 0.4576 - val_auc: 0.8538 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4135 - auc: 0.8717\n",
      "Epoch 112: val_loss did not improve from 0.45764\n",
      "819/819 [==============================] - 14s 17ms/step - loss: 0.4135 - auc: 0.8717 - val_loss: 0.4605 - val_auc: 0.8532 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4115 - auc: 0.8729\n",
      "Epoch 113: val_loss improved from 0.45764 to 0.45712, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.4115 - auc: 0.8728 - val_loss: 0.4571 - val_auc: 0.8551 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4106 - auc: 0.8733\n",
      "Epoch 114: val_loss did not improve from 0.45712\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.4106 - auc: 0.8733 - val_loss: 0.4577 - val_auc: 0.8561 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4110 - auc: 0.8734\n",
      "Epoch 115: val_loss improved from 0.45712 to 0.45365, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.4110 - auc: 0.8734 - val_loss: 0.4537 - val_auc: 0.8563 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4110 - auc: 0.8732\n",
      "Epoch 116: val_loss did not improve from 0.45365\n",
      "819/819 [==============================] - 18s 21ms/step - loss: 0.4110 - auc: 0.8732 - val_loss: 0.4580 - val_auc: 0.8529 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4093 - auc: 0.8745\n",
      "Epoch 117: val_loss did not improve from 0.45365\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 0.4093 - auc: 0.8745 - val_loss: 0.4573 - val_auc: 0.8544 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4083 - auc: 0.8749\n",
      "Epoch 118: val_loss did not improve from 0.45365\n",
      "819/819 [==============================] - 22s 27ms/step - loss: 0.4083 - auc: 0.8749 - val_loss: 0.4574 - val_auc: 0.8549 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4081 - auc: 0.8754\n",
      "Epoch 119: val_loss did not improve from 0.45365\n",
      "819/819 [==============================] - 25s 31ms/step - loss: 0.4081 - auc: 0.8754 - val_loss: 0.4603 - val_auc: 0.8542 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4079 - auc: 0.8757\n",
      "Epoch 120: val_loss improved from 0.45365 to 0.44952, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 24s 30ms/step - loss: 0.4079 - auc: 0.8757 - val_loss: 0.4495 - val_auc: 0.8576 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4053 - auc: 0.8771\n",
      "Epoch 121: val_loss did not improve from 0.44952\n",
      "819/819 [==============================] - 29s 35ms/step - loss: 0.4053 - auc: 0.8772 - val_loss: 0.4511 - val_auc: 0.8592 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4046 - auc: 0.8777\n",
      "Epoch 122: val_loss did not improve from 0.44952\n",
      "819/819 [==============================] - 28s 34ms/step - loss: 0.4046 - auc: 0.8777 - val_loss: 0.4528 - val_auc: 0.8581 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4046 - auc: 0.8776\n",
      "Epoch 123: val_loss did not improve from 0.44952\n",
      "819/819 [==============================] - 21s 26ms/step - loss: 0.4046 - auc: 0.8776 - val_loss: 0.4571 - val_auc: 0.8556 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.4047 - auc: 0.8779\n",
      "Epoch 124: val_loss did not improve from 0.44952\n",
      "819/819 [==============================] - 41s 50ms/step - loss: 0.4047 - auc: 0.8779 - val_loss: 0.4539 - val_auc: 0.8587 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4038 - auc: 0.8785\n",
      "Epoch 125: val_loss improved from 0.44952 to 0.44864, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 40s 49ms/step - loss: 0.4038 - auc: 0.8785 - val_loss: 0.4486 - val_auc: 0.8619 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4031 - auc: 0.8793\n",
      "Epoch 126: val_loss did not improve from 0.44864\n",
      "819/819 [==============================] - 23s 28ms/step - loss: 0.4031 - auc: 0.8792 - val_loss: 0.4553 - val_auc: 0.8544 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.4009 - auc: 0.8801\n",
      "Epoch 127: val_loss did not improve from 0.44864\n",
      "819/819 [==============================] - 30s 37ms/step - loss: 0.4009 - auc: 0.8801 - val_loss: 0.4500 - val_auc: 0.8620 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4002 - auc: 0.8808\n",
      "Epoch 128: val_loss did not improve from 0.44864\n",
      "819/819 [==============================] - 25s 31ms/step - loss: 0.4002 - auc: 0.8808 - val_loss: 0.4541 - val_auc: 0.8603 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.4020 - auc: 0.8798\n",
      "Epoch 129: val_loss did not improve from 0.44864\n",
      "819/819 [==============================] - 24s 30ms/step - loss: 0.4020 - auc: 0.8798 - val_loss: 0.4545 - val_auc: 0.8589 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.4001 - auc: 0.8808\n",
      "Epoch 130: val_loss did not improve from 0.44864\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.4001 - auc: 0.8808 - val_loss: 0.4521 - val_auc: 0.8609 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3839 - auc: 0.8905\n",
      "Epoch 131: val_loss improved from 0.44864 to 0.43779, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3839 - auc: 0.8905 - val_loss: 0.4378 - val_auc: 0.8738 - lr: 7.5000e-04\n",
      "Epoch 132/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3811 - auc: 0.8921\n",
      "Epoch 132: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3811 - auc: 0.8921 - val_loss: 0.4481 - val_auc: 0.8706 - lr: 7.5000e-04\n",
      "Epoch 133/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3803 - auc: 0.8926\n",
      "Epoch 133: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3803 - auc: 0.8926 - val_loss: 0.4436 - val_auc: 0.8714 - lr: 7.5000e-04\n",
      "Epoch 134/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3784 - auc: 0.8943\n",
      "Epoch 134: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3783 - auc: 0.8943 - val_loss: 0.4439 - val_auc: 0.8730 - lr: 7.5000e-04\n",
      "Epoch 135/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3766 - auc: 0.8952\n",
      "Epoch 135: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.3766 - auc: 0.8952 - val_loss: 0.4395 - val_auc: 0.8747 - lr: 7.5000e-04\n",
      "Epoch 136/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3757 - auc: 0.8958\n",
      "Epoch 136: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 27s 33ms/step - loss: 0.3757 - auc: 0.8958 - val_loss: 0.4420 - val_auc: 0.8740 - lr: 7.5000e-04\n",
      "Epoch 137/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3758 - auc: 0.8958\n",
      "Epoch 137: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.3758 - auc: 0.8958 - val_loss: 0.4411 - val_auc: 0.8762 - lr: 7.5000e-04\n",
      "Epoch 138/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3722 - auc: 0.8977\n",
      "Epoch 138: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 21s 25ms/step - loss: 0.3722 - auc: 0.8977 - val_loss: 0.4390 - val_auc: 0.8776 - lr: 7.5000e-04\n",
      "Epoch 139/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3720 - auc: 0.8976\n",
      "Epoch 139: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 18s 22ms/step - loss: 0.3720 - auc: 0.8976 - val_loss: 0.4463 - val_auc: 0.8733 - lr: 7.5000e-04\n",
      "Epoch 140/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3718 - auc: 0.8980\n",
      "Epoch 140: val_loss did not improve from 0.43779\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3718 - auc: 0.8980 - val_loss: 0.4463 - val_auc: 0.8709 - lr: 7.5000e-04\n",
      "Epoch 141/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3709 - auc: 0.8985\n",
      "Epoch 141: val_loss did not improve from 0.43779\n",
      "\n",
      "Epoch 141: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3710 - auc: 0.8985 - val_loss: 0.4405 - val_auc: 0.8771 - lr: 7.5000e-04\n",
      "Epoch 142/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3562 - auc: 0.9068\n",
      "Epoch 142: val_loss improved from 0.43779 to 0.43698, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.3562 - auc: 0.9067 - val_loss: 0.4370 - val_auc: 0.8845 - lr: 5.6250e-04\n",
      "Epoch 143/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3532 - auc: 0.9084\n",
      "Epoch 143: val_loss did not improve from 0.43698\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.3532 - auc: 0.9084 - val_loss: 0.4423 - val_auc: 0.8829 - lr: 5.6250e-04\n",
      "Epoch 144/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3522 - auc: 0.9091\n",
      "Epoch 144: val_loss did not improve from 0.43698\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3523 - auc: 0.9091 - val_loss: 0.4387 - val_auc: 0.8870 - lr: 5.6250e-04\n",
      "Epoch 145/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3509 - auc: 0.9099\n",
      "Epoch 145: val_loss improved from 0.43698 to 0.43518, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.3509 - auc: 0.9099 - val_loss: 0.4352 - val_auc: 0.8873 - lr: 5.6250e-04\n",
      "Epoch 146/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3495 - auc: 0.9109\n",
      "Epoch 146: val_loss did not improve from 0.43518\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.3495 - auc: 0.9109 - val_loss: 0.4359 - val_auc: 0.8873 - lr: 5.6250e-04\n",
      "Epoch 147/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3471 - auc: 0.9119\n",
      "Epoch 147: val_loss did not improve from 0.43518\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.3471 - auc: 0.9119 - val_loss: 0.4361 - val_auc: 0.8886 - lr: 5.6250e-04\n",
      "Epoch 148/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3453 - auc: 0.9127\n",
      "Epoch 148: val_loss did not improve from 0.43518\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3453 - auc: 0.9127 - val_loss: 0.4353 - val_auc: 0.8909 - lr: 5.6250e-04\n",
      "Epoch 149/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3461 - auc: 0.9127\n",
      "Epoch 149: val_loss improved from 0.43518 to 0.43511, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3461 - auc: 0.9127 - val_loss: 0.4351 - val_auc: 0.8892 - lr: 5.6250e-04\n",
      "Epoch 150/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3436 - auc: 0.9137\n",
      "Epoch 150: val_loss did not improve from 0.43511\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3437 - auc: 0.9137 - val_loss: 0.4441 - val_auc: 0.8871 - lr: 5.6250e-04\n",
      "Epoch 151/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3436 - auc: 0.9138\n",
      "Epoch 151: val_loss did not improve from 0.43511\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3436 - auc: 0.9138 - val_loss: 0.4387 - val_auc: 0.8910 - lr: 5.6250e-04\n",
      "Epoch 152/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3421 - auc: 0.9150\n",
      "Epoch 152: val_loss did not improve from 0.43511\n",
      "819/819 [==============================] - 14s 18ms/step - loss: 0.3421 - auc: 0.9150 - val_loss: 0.4379 - val_auc: 0.8896 - lr: 5.6250e-04\n",
      "Epoch 153/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3408 - auc: 0.9155\n",
      "Epoch 153: val_loss did not improve from 0.43511\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3409 - auc: 0.9155 - val_loss: 0.4354 - val_auc: 0.8935 - lr: 5.6250e-04\n",
      "Epoch 154/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3405 - auc: 0.9158\n",
      "Epoch 154: val_loss did not improve from 0.43511\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3405 - auc: 0.9158 - val_loss: 0.4427 - val_auc: 0.8884 - lr: 5.6250e-04\n",
      "Epoch 155/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3403 - auc: 0.9161\n",
      "Epoch 155: val_loss improved from 0.43511 to 0.42843, saving model to .\\Keylogging.h5\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3403 - auc: 0.9161 - val_loss: 0.4284 - val_auc: 0.8945 - lr: 5.6250e-04\n",
      "Epoch 156/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3380 - auc: 0.9171\n",
      "Epoch 156: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3380 - auc: 0.9171 - val_loss: 0.4363 - val_auc: 0.8907 - lr: 5.6250e-04\n",
      "Epoch 157/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3375 - auc: 0.9174\n",
      "Epoch 157: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3375 - auc: 0.9174 - val_loss: 0.4326 - val_auc: 0.8932 - lr: 5.6250e-04\n",
      "Epoch 158/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3376 - auc: 0.9176\n",
      "Epoch 158: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3376 - auc: 0.9175 - val_loss: 0.4304 - val_auc: 0.8939 - lr: 5.6250e-04\n",
      "Epoch 159/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3355 - auc: 0.9184\n",
      "Epoch 159: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3355 - auc: 0.9183 - val_loss: 0.4369 - val_auc: 0.8941 - lr: 5.6250e-04\n",
      "Epoch 160/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3347 - auc: 0.9189\n",
      "Epoch 160: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3347 - auc: 0.9189 - val_loss: 0.4350 - val_auc: 0.8943 - lr: 5.6250e-04\n",
      "Epoch 161/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3346 - auc: 0.9191\n",
      "Epoch 161: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3346 - auc: 0.9191 - val_loss: 0.4329 - val_auc: 0.8935 - lr: 5.6250e-04\n",
      "Epoch 162/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3341 - auc: 0.9193\n",
      "Epoch 162: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3341 - auc: 0.9193 - val_loss: 0.4329 - val_auc: 0.8951 - lr: 5.6250e-04\n",
      "Epoch 163/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3322 - auc: 0.9203\n",
      "Epoch 163: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3322 - auc: 0.9203 - val_loss: 0.4328 - val_auc: 0.8974 - lr: 5.6250e-04\n",
      "Epoch 164/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3320 - auc: 0.9204\n",
      "Epoch 164: val_loss did not improve from 0.42843\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.3320 - auc: 0.9204 - val_loss: 0.4365 - val_auc: 0.8941 - lr: 5.6250e-04\n",
      "Epoch 165/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3320 - auc: 0.9203\n",
      "Epoch 165: val_loss improved from 0.42843 to 0.42810, saving model to .\\Keylogging.h5\n",
      "\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.3320 - auc: 0.9203 - val_loss: 0.4281 - val_auc: 0.8984 - lr: 5.6250e-04\n",
      "Epoch 166/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3151 - auc: 0.9286\n",
      "Epoch 166: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3151 - auc: 0.9285 - val_loss: 0.4303 - val_auc: 0.9035 - lr: 4.2187e-04\n",
      "Epoch 167/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3129 - auc: 0.9294\n",
      "Epoch 167: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3129 - auc: 0.9294 - val_loss: 0.4305 - val_auc: 0.9063 - lr: 4.2187e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3136 - auc: 0.9293\n",
      "Epoch 168: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 23s 28ms/step - loss: 0.3136 - auc: 0.9293 - val_loss: 0.4337 - val_auc: 0.9038 - lr: 4.2187e-04\n",
      "Epoch 169/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.3124 - auc: 0.9297\n",
      "Epoch 169: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 30s 37ms/step - loss: 0.3124 - auc: 0.9297 - val_loss: 0.4299 - val_auc: 0.9054 - lr: 4.2187e-04\n",
      "Epoch 170/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3106 - auc: 0.9307\n",
      "Epoch 170: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.3106 - auc: 0.9307 - val_loss: 0.4358 - val_auc: 0.9048 - lr: 4.2187e-04\n",
      "Epoch 171/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3105 - auc: 0.9309\n",
      "Epoch 171: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.3105 - auc: 0.9309 - val_loss: 0.4320 - val_auc: 0.9082 - lr: 4.2187e-04\n",
      "Epoch 172/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3074 - auc: 0.9322\n",
      "Epoch 172: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.3074 - auc: 0.9322 - val_loss: 0.4340 - val_auc: 0.9070 - lr: 4.2187e-04\n",
      "Epoch 173/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.3072 - auc: 0.9324\n",
      "Epoch 173: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 20ms/step - loss: 0.3072 - auc: 0.9324 - val_loss: 0.4412 - val_auc: 0.9077 - lr: 4.2187e-04\n",
      "Epoch 174/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.3064 - auc: 0.9328\n",
      "Epoch 174: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 20s 25ms/step - loss: 0.3063 - auc: 0.9329 - val_loss: 0.4377 - val_auc: 0.9086 - lr: 4.2187e-04\n",
      "Epoch 175/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.3052 - auc: 0.9335\n",
      "Epoch 175: val_loss did not improve from 0.42810\n",
      "\n",
      "Epoch 175: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "819/819 [==============================] - 26s 32ms/step - loss: 0.3052 - auc: 0.9335 - val_loss: 0.4377 - val_auc: 0.9100 - lr: 4.2187e-04\n",
      "Epoch 176/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2921 - auc: 0.9391\n",
      "Epoch 176: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 24s 29ms/step - loss: 0.2921 - auc: 0.9391 - val_loss: 0.4409 - val_auc: 0.9139 - lr: 3.1641e-04\n",
      "Epoch 177/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2894 - auc: 0.9403\n",
      "Epoch 177: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.2894 - auc: 0.9403 - val_loss: 0.4464 - val_auc: 0.9153 - lr: 3.1641e-04\n",
      "Epoch 178/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.2886 - auc: 0.9407\n",
      "Epoch 178: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.2886 - auc: 0.9407 - val_loss: 0.4486 - val_auc: 0.9150 - lr: 3.1641e-04\n",
      "Epoch 179/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2872 - auc: 0.9411\n",
      "Epoch 179: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 20ms/step - loss: 0.2872 - auc: 0.9411 - val_loss: 0.4518 - val_auc: 0.9142 - lr: 3.1641e-04\n",
      "Epoch 180/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.2856 - auc: 0.9420\n",
      "Epoch 180: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.2856 - auc: 0.9419 - val_loss: 0.4606 - val_auc: 0.9133 - lr: 3.1641e-04\n",
      "Epoch 181/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2847 - auc: 0.9424\n",
      "Epoch 181: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.2847 - auc: 0.9424 - val_loss: 0.4514 - val_auc: 0.9171 - lr: 3.1641e-04\n",
      "Epoch 182/1000\n",
      "815/819 [============================>.] - ETA: 0s - loss: 0.2827 - auc: 0.9433\n",
      "Epoch 182: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 15s 18ms/step - loss: 0.2827 - auc: 0.9433 - val_loss: 0.4552 - val_auc: 0.9179 - lr: 3.1641e-04\n",
      "Epoch 183/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2818 - auc: 0.9435\n",
      "Epoch 183: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.2818 - auc: 0.9435 - val_loss: 0.4586 - val_auc: 0.9176 - lr: 3.1641e-04\n",
      "Epoch 184/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2820 - auc: 0.9436\n",
      "Epoch 184: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.2820 - auc: 0.9436 - val_loss: 0.4596 - val_auc: 0.9178 - lr: 3.1641e-04\n",
      "Epoch 185/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2798 - auc: 0.9445\n",
      "Epoch 185: val_loss did not improve from 0.42810\n",
      "\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "819/819 [==============================] - 15s 19ms/step - loss: 0.2798 - auc: 0.9445 - val_loss: 0.4590 - val_auc: 0.9193 - lr: 3.1641e-04\n",
      "Epoch 186/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.2682 - auc: 0.9492\n",
      "Epoch 186: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 16s 19ms/step - loss: 0.2682 - auc: 0.9492 - val_loss: 0.4573 - val_auc: 0.9246 - lr: 2.3730e-04\n",
      "Epoch 187/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2657 - auc: 0.9502\n",
      "Epoch 187: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.2657 - auc: 0.9502 - val_loss: 0.4658 - val_auc: 0.9241 - lr: 2.3730e-04\n",
      "Epoch 188/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2652 - auc: 0.9503\n",
      "Epoch 188: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 18s 21ms/step - loss: 0.2652 - auc: 0.9503 - val_loss: 0.4736 - val_auc: 0.9230 - lr: 2.3730e-04\n",
      "Epoch 189/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2645 - auc: 0.9507\n",
      "Epoch 189: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.2645 - auc: 0.9507 - val_loss: 0.4699 - val_auc: 0.9256 - lr: 2.3730e-04\n",
      "Epoch 190/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2621 - auc: 0.9515\n",
      "Epoch 190: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.2621 - auc: 0.9515 - val_loss: 0.4790 - val_auc: 0.9247 - lr: 2.3730e-04\n",
      "Epoch 191/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2620 - auc: 0.9516\n",
      "Epoch 191: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.2621 - auc: 0.9516 - val_loss: 0.4836 - val_auc: 0.9242 - lr: 2.3730e-04\n",
      "Epoch 192/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2616 - auc: 0.9518\n",
      "Epoch 192: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 17s 21ms/step - loss: 0.2616 - auc: 0.9518 - val_loss: 0.4869 - val_auc: 0.9252 - lr: 2.3730e-04\n",
      "Epoch 193/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2599 - auc: 0.9524\n",
      "Epoch 193: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 18s 21ms/step - loss: 0.2598 - auc: 0.9524 - val_loss: 0.4830 - val_auc: 0.9272 - lr: 2.3730e-04\n",
      "Epoch 194/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2584 - auc: 0.9530\n",
      "Epoch 194: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 29s 36ms/step - loss: 0.2584 - auc: 0.9530 - val_loss: 0.4854 - val_auc: 0.9277 - lr: 2.3730e-04\n",
      "Epoch 195/1000\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2577 - auc: 0.9534\n",
      "Epoch 195: val_loss did not improve from 0.42810\n",
      "\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.00017797851614886895.\n",
      "819/819 [==============================] - 36s 44ms/step - loss: 0.2577 - auc: 0.9534 - val_loss: 0.4976 - val_auc: 0.9253 - lr: 2.3730e-04\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "818/819 [============================>.] - ETA: 0s - loss: 0.2478 - auc: 0.9571\n",
      "Epoch 196: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 19s 23ms/step - loss: 0.2478 - auc: 0.9571 - val_loss: 0.5026 - val_auc: 0.9299 - lr: 1.7798e-04\n",
      "Epoch 197/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2458 - auc: 0.9578\n",
      "Epoch 197: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 22s 27ms/step - loss: 0.2458 - auc: 0.9578 - val_loss: 0.5063 - val_auc: 0.9300 - lr: 1.7798e-04\n",
      "Epoch 198/1000\n",
      "818/819 [============================>.] - ETA: 0s - loss: 0.2450 - auc: 0.9580\n",
      "Epoch 198: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 24s 30ms/step - loss: 0.2450 - auc: 0.9580 - val_loss: 0.5124 - val_auc: 0.9320 - lr: 1.7798e-04\n",
      "Epoch 199/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2445 - auc: 0.9583\n",
      "Epoch 199: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 25s 30ms/step - loss: 0.2445 - auc: 0.9583 - val_loss: 0.5134 - val_auc: 0.9317 - lr: 1.7798e-04\n",
      "Epoch 200/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2441 - auc: 0.9583\n",
      "Epoch 200: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 21s 26ms/step - loss: 0.2441 - auc: 0.9583 - val_loss: 0.5164 - val_auc: 0.9328 - lr: 1.7798e-04\n",
      "Epoch 201/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.2420 - auc: 0.9591\n",
      "Epoch 201: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 21s 25ms/step - loss: 0.2420 - auc: 0.9591 - val_loss: 0.5212 - val_auc: 0.9326 - lr: 1.7798e-04\n",
      "Epoch 202/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2419 - auc: 0.9592\n",
      "Epoch 202: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 20s 25ms/step - loss: 0.2419 - auc: 0.9592 - val_loss: 0.5258 - val_auc: 0.9330 - lr: 1.7798e-04\n",
      "Epoch 203/1000\n",
      "816/819 [============================>.] - ETA: 0s - loss: 0.2402 - auc: 0.9597\n",
      "Epoch 203: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 21s 26ms/step - loss: 0.2403 - auc: 0.9597 - val_loss: 0.5349 - val_auc: 0.9310 - lr: 1.7798e-04\n",
      "Epoch 204/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2397 - auc: 0.9600\n",
      "Epoch 204: val_loss did not improve from 0.42810\n",
      "819/819 [==============================] - 20s 25ms/step - loss: 0.2397 - auc: 0.9600 - val_loss: 0.5320 - val_auc: 0.9335 - lr: 1.7798e-04\n",
      "Epoch 205/1000\n",
      "817/819 [============================>.] - ETA: 0s - loss: 0.2380 - auc: 0.9606\n",
      "Epoch 205: val_loss did not improve from 0.42810\n",
      "Restoring model weights from the end of the best epoch: 155.\n",
      "\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 0.0001334838816546835.\n",
      "819/819 [==============================] - 21s 25ms/step - loss: 0.2380 - auc: 0.9606 - val_loss: 0.5404 - val_auc: 0.9329 - lr: 1.7798e-04\n",
      "Epoch 205: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks = [model_save, early_stop, reduce_lr],\n",
    "          verbose=1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743181d9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73263d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.895\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "AUC1 = metrics.roc_auc_score(y_test,y_pred)\n",
    "print(\"AUC: {:.3f}\".format(AUC1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "406796f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model=[]\n",
    "scores_model.append({'Model': 'ANN','AUC_Score': AUC1})\n",
    "import pickle\n",
    "with open('ANN1Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model1, file)\n",
    "hist_df1 = pd.DataFrame(history1.history)\n",
    "hist_df1.to_csv('history1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a094a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels.append(model1)\n",
    "DLhistory.append(history1)\n",
    "AUCVal.append(AUC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b6ca5",
   "metadata": {},
   "source": [
    "# Deep Learning Model 2 -SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93369265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 19\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
    "    model2 = Sequential()\n",
    "    model2.add(SimpleRNN(3, input_shape=(X_test.shape[1],1), activation='sigmoid'))\n",
    "    \n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "    model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2ece43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6545/6545 [==============================] - 46s 7ms/step - loss: 0.6770 - accuracy: 0.5854\n",
      "Epoch 2/10\n",
      "6545/6545 [==============================] - 65s 10ms/step - loss: 0.6748 - accuracy: 0.5926\n",
      "Epoch 3/10\n",
      "6545/6545 [==============================] - 63s 10ms/step - loss: 0.6748 - accuracy: 0.5925\n",
      "Epoch 4/10\n",
      "6545/6545 [==============================] - 68s 10ms/step - loss: 0.6748 - accuracy: 0.5925\n",
      "Epoch 5/10\n",
      "6545/6545 [==============================] - 61s 9ms/step - loss: 0.6748 - accuracy: 0.5922\n",
      "Epoch 6/10\n",
      "6545/6545 [==============================] - 101s 15ms/step - loss: 0.6747 - accuracy: 0.5921\n",
      "Epoch 7/10\n",
      "6545/6545 [==============================] - 120s 18ms/step - loss: 0.6747 - accuracy: 0.5921\n",
      "Epoch 8/10\n",
      "6545/6545 [==============================] - 126s 19ms/step - loss: 0.6747 - accuracy: 0.5922\n",
      "Epoch 9/10\n",
      "6545/6545 [==============================] - 129s 20ms/step - loss: 0.6747 - accuracy: 0.5919\n",
      "Epoch 10/10\n",
      "6545/6545 [==============================] - 134s 20ms/step - loss: 0.6747 - accuracy: 0.5921\n"
     ]
    }
   ],
   "source": [
    "history2=model2.fit(X_train,\n",
    "          y_train, epochs=10, batch_size=64*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c3b2b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6616b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.520\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model2.predict(X_test)\n",
    "AUC2 = metrics.roc_auc_score(y_test,y_pred2)\n",
    "print(\"AUC: {:.3f}\".format(AUC2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ed92707",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'SimpleRNN','AUC_Score': AUC2})\n",
    "import pickle\n",
    "with open('SimpleRNN1Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model2, file)\n",
    "hist_df2 = pd.DataFrame(history2.history)\n",
    "hist_df2.to_csv('history2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71aabafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels.append(model2)\n",
    "DLhistory.append(history2)\n",
    "AUCVal.append(AUC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cef5a",
   "metadata": {},
   "source": [
    "## Deep Learning Model-3 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52c15b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 454 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    \n",
    "    # A simple LSTM with glove embeddings and one dense layer\n",
    "    model3 = Sequential()\n",
    "\n",
    "    model3.add(LSTM(100,  input_shape=(X_test.shape[1],1),dropout=0.3, recurrent_dropout=0.3))\n",
    "    model3.add(Dense(1, activation='sigmoid'))\n",
    "    model3.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2429bfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6545/6545 [==============================] - 1262s 191ms/step - loss: 0.6743 - accuracy: 0.5913\n",
      "Epoch 2/5\n",
      "6545/6545 [==============================] - 1413s 216ms/step - loss: 0.6738 - accuracy: 0.5918\n",
      "Epoch 3/5\n",
      "6545/6545 [==============================] - 1391s 212ms/step - loss: 0.6739 - accuracy: 0.5923\n",
      "Epoch 4/5\n",
      "6545/6545 [==============================] - 891s 136ms/step - loss: 0.6734 - accuracy: 0.5923\n",
      "Epoch 5/5\n",
      "6545/6545 [==============================] - 867s 132ms/step - loss: 0.6685 - accuracy: 0.5994\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train,y_train, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209d9d0",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceda2c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.583\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = model3.predict(X_test)\n",
    "AUC3 = metrics.roc_auc_score(y_test,y_pred3)\n",
    "print(\"AUC: {:.3f}\".format(AUC3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a5276b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'LSTM','AUC_Score': AUC3})\n",
    "import pickle\n",
    "with open('LSTM1Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model3, file)\n",
    "hist_df3 = pd.DataFrame(history3.history)\n",
    "hist_df3.to_csv('history3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3073ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels.append(model3)\n",
    "DLhistory.append(history3)\n",
    "AUCVal.append(AUC3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f74d9b",
   "metadata": {},
   "source": [
    "## Deep Learning Model 4:GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a3439ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 300)               271800    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272,101\n",
      "Trainable params: 272,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 294 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # GRU with glove embeddings and two dense layers\n",
    "    model4 = Sequential()\n",
    "    \n",
    "    model4.add(GRU(300,input_shape=(X_test.shape[1],1)))\n",
    "    model4.add(Dense(1, activation='sigmoid'))\n",
    "    model4.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n",
    "    \n",
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59ba55d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6545/6545 [==============================] - 2961s 451ms/step - loss: 0.6750 - accuracy: 0.5923\n",
      "Epoch 2/5\n",
      "6545/6545 [==============================] - 2934s 448ms/step - loss: 0.6722 - accuracy: 0.5951\n",
      "Epoch 3/5\n",
      "6545/6545 [==============================] - 2938s 449ms/step - loss: 0.6518 - accuracy: 0.6190\n",
      "Epoch 4/5\n",
      "6545/6545 [==============================] - 2921s 446ms/step - loss: 0.6348 - accuracy: 0.6327\n",
      "Epoch 5/5\n",
      "6545/6545 [==============================] - 2876s 439ms/step - loss: 0.6237 - accuracy: 0.6425\n"
     ]
    }
   ],
   "source": [
    "history4=model4.fit(X_train, y_train, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c0c2d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33618f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.670\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = model4.predict(X_test)\n",
    "AUC4 = metrics.roc_auc_score(y_test,y_pred4)\n",
    "print(\"AUC: {:.3f}\".format(AUC4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16b91af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'GRU','AUC_Score': AUC4})\n",
    "import pickle\n",
    "with open('GRU1Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model4, file)\n",
    "hist_df3 = pd.DataFrame(history4.history)\n",
    "hist_df3.to_csv('history4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "624d4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels.append(model4)\n",
    "DLhistory.append(history4)\n",
    "AUCVal.append(AUC4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9b701",
   "metadata": {},
   "source": [
    "## Deep Learning Model 5: BiDirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7d1e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 600)              724800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 601       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 725,401\n",
      "Trainable params: 725,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # A simple bidirectional LSTM with glove embeddings and one dense layer\n",
    "    model5 = Sequential()\n",
    "    model5.add(Bidirectional(LSTM(300),input_shape=(X_test.shape[1],1)))\n",
    "\n",
    "    model5.add(Dense(1,activation='sigmoid'))\n",
    "    model5.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "832d4eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6545/6545 [==============================] - 5004s 763ms/step - loss: 0.6740 - accuracy: 0.5928\n",
      "Epoch 2/5\n",
      "6545/6545 [==============================] - 4012s 613ms/step - loss: 0.6701 - accuracy: 0.5977\n",
      "Epoch 3/5\n",
      "6545/6545 [==============================] - 4252s 650ms/step - loss: 0.6598 - accuracy: 0.6100\n",
      "Epoch 4/5\n",
      "6545/6545 [==============================] - 4099s 626ms/step - loss: 0.6476 - accuracy: 0.6212\n",
      "Epoch 5/5\n",
      "6545/6545 [==============================] - 4617s 705ms/step - loss: 0.6369 - accuracy: 0.6304\n"
     ]
    }
   ],
   "source": [
    "history5=model5.fit(X_train, y_train, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70577c75",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0de8b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.651\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = model5.predict(X_test)\n",
    "AUC5 = metrics.roc_auc_score(y_test,y_pred5)\n",
    "print(\"AUC: {:.3f}\".format(AUC5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e35738b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'BiderctionalRNN','AUC_Score': AUC5})\n",
    "import pickle\n",
    "with open('BiRNN1Model.pkl', 'wb') as file:\n",
    "    pickle.dump(model5, file)\n",
    "hist_df5 = pd.DataFrame(history5.history)\n",
    "hist_df5.to_csv('history5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c43f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodels.append(model5)\n",
    "DLhistory.append(history5)\n",
    "AUCVal.append(AUC5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2064e",
   "metadata": {},
   "source": [
    "## Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3fa8386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2b65e_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b65e_row1_col1 {\n",
       "  background-color: #94c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b65e_row2_col1 {\n",
       "  background-color: #a6cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b65e_row3_col1 {\n",
       "  background-color: #d6e5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b65e_row4_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b65e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >AUC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b65e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2b65e_row0_col0\" class=\"data row0 col0\" >ANN</td>\n",
       "      <td id=\"T_2b65e_row0_col1\" class=\"data row0 col1\" >0.894996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b65e_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_2b65e_row1_col0\" class=\"data row1 col0\" >GRU</td>\n",
       "      <td id=\"T_2b65e_row1_col1\" class=\"data row1 col1\" >0.669568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b65e_level0_row2\" class=\"row_heading level0 row2\" >4</th>\n",
       "      <td id=\"T_2b65e_row2_col0\" class=\"data row2 col0\" >BiderctionalRNN</td>\n",
       "      <td id=\"T_2b65e_row2_col1\" class=\"data row2 col1\" >0.651496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b65e_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_2b65e_row3_col0\" class=\"data row3 col0\" >LSTM</td>\n",
       "      <td id=\"T_2b65e_row3_col1\" class=\"data row3 col1\" >0.583235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b65e_level0_row4\" class=\"row_heading level0 row4\" >1</th>\n",
       "      <td id=\"T_2b65e_row4_col0\" class=\"data row4 col0\" >SimpleRNN</td>\n",
       "      <td id=\"T_2b65e_row4_col1\" class=\"data row4 col1\" >0.520050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28ca4460548>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualization of Results obtained from various Deep learning models\n",
    "results = pd.DataFrame(scores_model).sort_values(by='AUC_Score',ascending=False)\n",
    "results.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ef29e",
   "metadata": {},
   "source": [
    "## Best Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad0858",
   "metadata": {},
   "source": [
    "### Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "956b88c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(history1.epoch[-1]+1),history1.history['val_auc'],label='val_auc')\n",
    "plt.plot(range(history1.epoch[-1]+1),history1.history['auc'],label='auc')\n",
    "plt.title('auc'); plt.xlabel('Epoch'); plt.ylabel('auc');plt.legend(); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb66508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(history1.epoch[-1]+1),history1.history['val_loss'],label='Val_loss')\n",
    "plt.plot(range(history1.epoch[-1]+1),history1.history['loss'],label='loss')\n",
    "plt.title('loss'); plt.xlabel('Epoch'); plt.ylabel('loss');plt.legend(); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692515f8",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7f20069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_results(y_test, y_score):\n",
    "    # print(y_score)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "generate_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0276ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
